{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e984682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from network.unet import Unet\n",
    "from network.feature_extractor import ResNet, ResnetOriginal\n",
    "from network.full_model import EndNetwork, FullModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from datasets import LoadDataset, CustomOutput, Knit\n",
    "from datasets.custom_output import image_tensor, study_label_5\n",
    "\n",
    "from train.full import FullTrainingCLI\n",
    "\n",
    "from network.helper_functions import get_confusion_matrix\n",
    "\n",
    "from utils.device import device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6983364c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1db8c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--do-batch-norm',\n",
       " '--epochs=200',\n",
       " '--batch-size=100',\n",
       " '--unet-weights=_trainings/22-09_17-30_aDAOG_cB3D_b24_e200_BN_lr0.01_lrsp10/unet_e200.ckpt',\n",
       " '--resnet-weights=_weights/balanced_BCEwLLoss_labels0_resnet18_e12.ckpt',\n",
       " '--resnet-fc-cutoff=9',\n",
       " '--learning-rate=0.0001',\n",
       " '--use-lr-scheduler',\n",
       " '--lr-sch-patience=5',\n",
       " '--resnet-no-sigmoid-activation',\n",
       " '--criterion=CEBAL',\n",
       " '--resnet-trainable',\n",
       " '--cuda-device=1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsn = 0\n",
    "args_list = f'--do-batch-norm --epochs=200 --batch-size=100 --unet-weights=_trainings/22-09_17-30_aDAOG_cB3D_b24_e200_BN_lr0.01_lrsp10/unet_e200.ckpt --resnet-weights=_weights/balanced_BCEwLLoss_labels{labelsn}_resnet18_e12.ckpt --resnet-fc-cutoff=9 --learning-rate=0.0001 --use-lr-scheduler --lr-sch-patience=5 --resnet-no-sigmoid-activation --criterion=CEBAL --resnet-trainable --cuda-device=1'.split(' ')\n",
    "args_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f74c1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(absolute_training_size=5200, adam_regul_factor=0, augmentation=<Augmentation.NA: <trafo.compose.Compose object at 0x7f1f2ddc4650>>, batch_size=100, criterion=<Criterion.CEBAL: CrossEntropyLoss()>, cuda_device=1, do_batch_norm=True, epochs=200, feature_shape=512, get_abbrev_only=False, get_cuda_device_count_only=False, get_path_only=False, learning_rate=0.0001, lr_sch_patience=5, no_drop_last=False, no_dropout=False, path=None, path_prefix='_full_training', resnet_fc_cutoff=9, resnet_no_sigmoid_activation=True, resnet_out_shape=None, resnet_trainable=True, resnet_weights='_weights/balanced_BCEwLLoss_labels0_resnet18_e12.ckpt', unet_trainable=False, unet_weights='_trainings/22-09_17-30_aDAOG_cB3D_b24_e200_BN_lr0.01_lrsp10/unet_e200.ckpt', use_lr_scheduler=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli = FullTrainingCLI()\n",
    "args = cli.get_args(*args_list)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6bb0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load resnet from epoch 12\n"
     ]
    }
   ],
   "source": [
    "# Get Networks\n",
    "unet = Unet(batch_norm=args.do_batch_norm)\n",
    "unet.load_state_dict(torch.load(args.unet_weights,\n",
    "                                map_location=device))\n",
    "\n",
    "# Get ResNet\n",
    "pattern = re.compile(r\"(_e(\\d+)\\.ckpt)$\")\n",
    "load_epoch = int(pattern.search(args.resnet_weights).group(2))\n",
    "print(\"Attempting to load resnet from epoch\", load_epoch)\n",
    "resnet_config_file = pattern.sub(\"_net_config.json\",\n",
    "                                 args.resnet_weights)\n",
    "\n",
    "with open(resnet_config_file) as f:\n",
    "    resnet_config = json.load(f)\n",
    "\n",
    "sigmoid_activation = args.resnet_no_sigmoid_activation is not True\n",
    "if resnet_config[\"network\"] == \"ResNet\":\n",
    "    dims = [int(n) for n\n",
    "            in re.search(r\"resnet(\\d+)\", resnet_config_file).group(1)]\n",
    "    print(\"trying to load\", f\"dims={dims}\",\n",
    "          f\"out_shape={args.resnet_out_shape}\")\n",
    "    resnet = ResNet(dims, out_shape=args.resnet_out_shape,\n",
    "                    sigmoid_activation=sigmoid_activation)\n",
    "    resnet.load_state_dict(torch.load(args.resnet_weights,\n",
    "                                      map_location=device))\n",
    "    children = list(resnet.end.children())\n",
    "    # cut off everything from last Linear layer:\n",
    "    for i, child in enumerate(reversed(children)):\n",
    "        if isinstance(child, nn.Linear):\n",
    "            resnet.end = nn.Sequential(*children[:-1-i])\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError(\"No nn.Linear found in ResNet\")\n",
    "elif resnet_config[\"network\"] == \"ResnetOriginal\":\n",
    "    if args.resnet_fc_cutoff is None:\n",
    "        raise RuntimeError(\"Please specify --resnet-fc-cutoff=n\")\n",
    "    resnet_type = resnet_config[\"type\"]\n",
    "    shapes = list(resnet_config[\"shapes\"])\n",
    "    trainable_level = int(resnet_config[\"trainable_level\"])\n",
    "    trainable_resnet = bool(resnet_config[\"trainable_resnet\"])\n",
    "    resnet = ResnetOriginal(type=resnet_type, shapes=shapes,\n",
    "                            trainable_resnet=trainable_resnet,\n",
    "                            trainable_level=trainable_level,\n",
    "                            sigmoid_activation=sigmoid_activation)\n",
    "    resnet.load_state_dict(torch.load(args.resnet_weights,\n",
    "                                      map_location=device))\n",
    "    resnet.fc.block = nn.Sequential(*list(resnet.fc.block.children())\n",
    "                                    [:-args.resnet_fc_cutoff])\n",
    "\n",
    "# Full network\n",
    "end_network = EndNetwork(features_shape=args.feature_shape,\n",
    "                         use_dropout=args.no_dropout is not True)\n",
    "\n",
    "model = FullModel(unet=unet, feature_extractor=resnet, end=end_network,\n",
    "                  threshold=0.5,\n",
    "                  unet_trainable=args.unet_trainable,\n",
    "                  feature_extractor_trainable=args.resnet_trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c907990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  5200 Validation:  1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/patzig/AML_project/datasets/knit.py:53: UserWarning: Guessed image_ids from LoadDataset\n",
      "  warn(f\"Guessed {name} from {dataset.__class__.__name__}\")\n",
      "/home/students/patzig/AML_project/datasets/knit.py:55: UserWarning: NotImplementedError: bounding_boxes not guessable from LoadDataset\n",
      "  warn(f\"{e.__class__.__name__}: {e}\")\n",
      "/home/students/patzig/AML_project/datasets/knit.py:53: UserWarning: Guessed label_type from LoadDataset\n",
      "  warn(f\"Guessed {name} from {dataset.__class__.__name__}\")\n"
     ]
    }
   ],
   "source": [
    "loaded_data = LoadDataset(\"_data/preprocessed256_new\",\n",
    "                                  image_dtype=float, label_dtype=float)\n",
    "knit_data = Knit(loaded_data, study_csv=\"_data/train_study_level.csv\",\n",
    "                 image_csv=\"_data/train_image_level.csv\")\n",
    "dataset_plain = CustomOutput(knit_data, image_tensor, study_label_5)\n",
    "dataset_aug = CustomOutput(knit_data, image_tensor, study_label_5,\n",
    "                           trafo=args.augmentation.value)\n",
    "dataset_aug.trafo.max_transformands = 1\n",
    "\n",
    "l_data = len(dataset_aug)\n",
    "indices = list(range(l_data))\n",
    "train_size = args.absolute_training_size\n",
    "val_size = l_data - train_size\n",
    "print(\"Training: \", train_size, \"Validation: \", val_size)\n",
    "\n",
    "train_indices, val_indices = train_test_split(indices, random_state=4,\n",
    "                                              train_size=train_size,\n",
    "                                              test_size=val_size)\n",
    "\n",
    "train_set = Subset(dataset_aug, train_indices)\n",
    "val_set = Subset(dataset_plain, val_indices)\n",
    "\n",
    "dataloader_train = DataLoader(train_set,\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=True, num_workers=0)\n",
    "dataloader_val = DataLoader(val_set,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True, num_workers=0,\n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d888075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199,  16,  79,   8,   2],\n",
       "       [ 32, 348, 110,  12,  11],\n",
       "       [ 44,  67,  61,  10,   4],\n",
       "       [  7,  26,  31,   5,   3],\n",
       "       [  4,  28,   8,   3,  16]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(model.cuda(), dataloader_val) # nach 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "994dcffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"_full_training/25-09_15-42_aNA_cCEBAL_b100_e200_BN_lr0.0001_lrsp5_nosig_fcc9/_e100.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b23c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[197,  16,  79,  10,   2],\n",
       "       [ 32, 341, 117,  12,  11],\n",
       "       [ 42,  65,  65,  10,   4],\n",
       "       [  7,  23,  32,   8,   2],\n",
       "       [  4,  26,  10,   3,  16]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(model.cuda(), dataloader_val) # nach 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef71e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,    5,   12,    0,    0],\n",
       "       [  17, 1994,  305,    1,   24],\n",
       "       [   0,   14,  841,    0,    8],\n",
       "       [   0,    0,    0,  319,    0],\n",
       "       [   0,    0,    0,    1,  244]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(model.cuda(), dataloader_train) # nach 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "718e6247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"_full_training/25-09_10-29_aNA_cCE_b100_e200_BN_lr1e-05_lrsp10_nosig_fcc9/_e100.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c86fc240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196,  16,  81,   9,   2],\n",
       "       [ 31, 348, 110,  13,  11],\n",
       "       [ 43,  67,  62,  10,   4],\n",
       "       [  7,  24,  32,   6,   3],\n",
       "       [  4,  28,   8,   3,  16]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(model.cuda(), dataloader_val) # nach 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74590204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1421,    4,    7,    0,    0],\n",
       "       [   4, 2123,  191,    1,   22],\n",
       "       [   0,    2,  853,    0,    8],\n",
       "       [   0,    0,    0,  318,    1],\n",
       "       [   0,    0,    0,    0,  245]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(model.cuda(), dataloader_train) # nach 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d4cf3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3334, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.2611, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0882, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0785, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0896, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0833, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0668, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0553, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0706, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0579, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0360, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0186, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0537, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0444, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0456, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0403, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0342, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0244, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0388, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-0.0133, device='cuda:0', grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for p in model.end.parameters():\n",
    "    print(torch.min(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e7ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml-venv-37",
   "language": "python",
   "name": "aml-venv-37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
